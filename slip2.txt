Q.1.
 A) Show practical examples to list files, Insert data, retrieving data,append to file and
shutting down HDFS. 

1) list of files 

hadoop fs -ls data\	        	(hadoop fs -ls /data)
Found 2 items
-rw-r--r--   1 Administrators None         15 2023-01-08 22:06 data/Two.txt
-rw-r--r--   1 Administrators None      43055 2023-01-08 20:33 data/one.txt


2) Insert data
hadoop fs -copyFromLocal "C:\Users\Acer\Desktop\four.txt" data	  (hadoop fs -copyFromLocal /opt/hadoop/BDA/a2.txt /SG)			

C:\hadoop-3.3.4\sbin>hadoop fs -ls data\								linux -> hadoop fs -ls /data
Found 3 items
-rw-r--r--   1 Administrators None         15 2023-01-08 22:06 data/Two.txt
-rw-r--r--   1 Administrators None         15 2023-01-08 22:44 data/four.txt
-rw-r--r--   1 Administrators None      43055 2023-01-08 20:33 data/one.txt

hadoop fs -cat data\four.txt									 (hadoop fs -cat /data/four.txt)
data is here...


3) retrive data
hadoop fs -copyToLocal data\four.txt "C:\Users\Acer\Desktop\new"			 (hadoop fs -copyToLocal /SG/P1.txt /opt/hadoop/Desktop/AAAA)

4) append file from local to hdfs 							(hadoop fs -appendToFile data.txt /test/test.txt)

hadoop fs -appendToFile "C:\Users\Acer\Desktop\three_new.txt" data \two.txt					
  (hadoop fs -appendToFile sorce folder name(local) destination folder name(hadoop))
appendToFile: File already exists: file:/C:/hadoop-3.3.4/sbin/two.txt

5) Shut down hdfs 
stop-dfs.sh

-----------------------------------------------------------------------------------------------

Q2: Write a MapReduce program to analyze weather data set and print whether the day is
shinny or cool day.Hint: Weather sensors collecting data every hour at many locations across
the globe gather a large volume of log data, which is a good candidate for analysis with Map
Reduce, since it is semi structured and record-oriented. 

// importing Libraries
import java.io.IOException;
import java.util.Iterator;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.conf.Configuration;

public class MyMaxMin {
	
	public static class MaxTemperatureMapper extends
			Mapper<LongWritable, Text, Text, Text> {

	public static final int MISSING = 9999;
		
	@Override
		public void map(LongWritable arg0, Text Value, Context context)
				throws IOException, InterruptedException {

		String line = Value.toString();
			

			if (!(line.length() == 0)) {
				
				
				String date = line.substring(6, 14);

				
				float temp_Max = Float.parseFloat(line.substring(39, 45).trim());
				

				
				float temp_Min = Float.parseFloat(line.substring(47, 53).trim());

				
				if (temp_Max > 30.0) {
					
					context.write(new Text("The Day is Hot Day :" + date),
										new Text(String.valueOf(temp_Max)));
				}

				
				if (temp_Min < 15) {
					
					context.write(new Text("The Day is Cold Day :" + date),
							new Text(String.valueOf(temp_Min)));
				}
			}
		}

	}


	
	public static class MaxTemperatureReducer extends
			Reducer<Text, Text, Text, Text> {


		
		public void reduce(Text Key, Iterator<Text> Values, Context context)
				throws IOException, InterruptedException {

			
			
			String temperature = Values.next().toString();
			context.write(Key, new Text(temperature));
		}

	}

	
	public static void main(String[] args) throws Exception {

		
		Configuration conf = new Configuration();
		
			
		Job job = new Job(conf, "weather example");
		
		// Assigning the driver class name
		job.setJarByClass(MyMaxMin.class);

		
		job.setMapOutputKeyClass(Text.class);
		
		
		job.setMapOutputValueClass(Text.class);

		
		job.setMapperClass(MaxTemperatureMapper.class);
		
		
		job.setReducerClass(MaxTemperatureReducer.class);

		
		job.setInputFormatClass(TextInputFormat.class);
		
		
		job.setOutputFormatClass(TextOutputFormat.class);

		
		Path OutputPath = new Path(args[1]);

		
		FileInputFormat.addInputPath(job, new Path(args[0]));

		
		FileOutputFormat.setOutputPath(job, new Path(args[1]));

		
		OutputPath.getFileSystem(conf).delete(OutputPath);

		
		System.exit(job.waitForCompletion(true) ? 0 : 1);

	}
}
